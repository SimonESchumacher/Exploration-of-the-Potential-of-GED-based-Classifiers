[GLOBAL]
# Global settings
DEBUG = false


[Experiment]
# Settings for the experiment.py script
DEBUG = true
# Fallback random State in the Experiment if not specified elsewhere
random_state = 42
# fallback test 
test_size = 0.2
report_setting = macro
# The interval that is calculated, along with the mean, for the error scores
errorinterval_setting = std_and_confidence_interval
confidence_interval_level = 0.95
# save the 
save_models = false
save_logs = true
dataset_hyperparams = false
calculator_hyperparams = false
# if a log of the hp tuning should return the train scores as well , would lead to larger log files, and potentailly increased tuning time.
return_train_score_hp_tuning = true
# if all model errors shoudl cause an error in the hp tuning, or just be logged and ignored.
error_score_hp_tuning = raise
[Dataset_loader]
# Settings for dataset loading and preprocessing in Dataset.py
DEBUG = true
random_state = 42
test_size = 0.2
# Filepath to the local datasets folder
local_data_path = Datasets
shuffle_default = true 
datasets_log = configs//test_datasets.xlsx

[main_experiment_run]
# Settings for the main experiment running script
CALCULATOR_NAME= Exact_GED
# Name of the heuristic calculator to use to compare to using GED
HEURISTIC_CALCULATOR_NAME=Heuristic_Calculator
HEURISTIC_BOUND=Vertex
# "grid" or "random" ; grid probably causes issues.
SEARCH_METHOD=random  
GED_BOUND=Exact
# eg "labels", "attributes" or None for both attributes currently not functional
nodes_and_edges= labels 
# testing level from 0-4
# 0 Speed Test Mode (only for for testing runtime and support vectors only)
# 1 only Speed Test
# 2 a test trail, with only 1 trail
# 3 test trail, but with full trials
# 4 Full Run with all tuning results saved
# 5 Full Run, with 5 iterations 
testing_level= 4
# ALL or a specific model
models_to_run= ALL
# e.g. "accuracy", "f1_macro", "roc_auc" 
tuning_metric=f1_macro
# Auto or specified number of jobs for parallel processing 
n_jobs= AUTO
# the split ratio for train and test when no predefined split is given
# recommended to be something that is a fraction 1/n where n is an integer.
split= 0.2
# if AUTO it will be set automatically, with a desicrptive name for result files. aditionnally the name can be set manually here.
experiment_name=AUTO 
# seconds, how often to save the intermediate results
INTERMEDIATE_SAVE_INTERVAL = 5  

[exact_GED_Calculator]
# Settings for the Exact_GED calculator
# timeout for the exact ged calculation in seconds
timeout= 450
# how many parallel jobs to use for the ged calculations, AUTO uses all available cores
n_jobs= 8
# if false remove the labels form the Dataset before calculating ged
labeld_datasets =true

[Hyperparameter_fields]
# how manny confgurations randomly sampled shoudl be used.
tuning_iterations =5
# SVC hyperparameter ranges
lower_C= 0.0005
upper_C= 10
# lambda hyperparameter ranges for the graph kernels tiv-GED, Diff-GED and RWE
lambdas_min= 0.005
lambdas_max= 0.95
# kNN hyperparameter ranges
min_neighbors= 1
max_neighbors= 7
# WL-ST depth ranges
wl_depth_min=1
wl_depth_max=7
# Number of iterations for the depth of Diff-GED ,RWE and RW
iteration_depth_min=2
iteration_depth_max=6
# for baseline Kernels, include normalizing the kernel matrix as an hyperparameter
include_kernel_normalization_options= false

[KNN]
debuging_prints= false

[SVC]
debuging_prints= false
# max number of iteration, after which fiting will stop, to avoid endless fitting
max_iter=10000000
# if true enable probability estimates
probability_estimates=true
# when the SVM shoudl call out a warning, that fitting of a model took too long.
fit_warning_threshold=10
# tolerance for stopping criterion
fitting_tolerance=0.0001
# size of the kernel cache in MB
cache_size=1000
# random state for reproducibility
default_random_state=42

[baseline_SVC]
debuging_prints= false

[GED_models]
debuging_prints= false
use_scaler=None

[GED_Calculator]
debuging_prints= false
# approximation method to use for the gedlibpy calculator
approximation_method =IPFP
approximation_bound =upper
# gedlibpy edit cost type to use
gedlib_edit_cost = CONSTANT

# enable to make random walk edit kernel possible
enable_node_mapping = true




